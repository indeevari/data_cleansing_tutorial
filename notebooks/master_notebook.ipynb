{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_cleansing_tutorial\n",
    "Data cleansing tutorial in Pandas for Chipy Scientific SIG\n",
    "\n",
    "## Introduction\n",
    "Data cleansing is an important part of the data analysis / data science workflow because in many cases, these practices require a very clean and standardized data set. Unfortunately, in many cases raw data sets usually contain potential errors such as containing missing values, coming in different file formats, redundancies, inconsistent naming, incorrect data types, just plain wrong values, amongst many problems. All of these concerns should be addressed in the data cleansing phase so that subsequent analysis proceeds smoothly and repeatably.\n",
    "\n",
    "## Goals\n",
    "### Goals for this tutorial\n",
    "- Introduce some commonly used data cleansing techniques in Pandas including:\n",
    "    - Data import from CSV (excel and stuff to come later)\n",
    "    - Pandas Series and DataFrames\n",
    "    - Simple exploration and summaries of data\n",
    "    - Selecting data\n",
    "    - Adding and removing data\n",
    "    - Removing nulls\n",
    "    - Fixing data types\n",
    "    - Sorting\n",
    "    - Concatenation and joining\n",
    "    - Aggregations and group operations\n",
    "    - Simple plotting (more to come in a separate tutorial)\n",
    "\n",
    "### Goals for this example study\n",
    "With all the media about vaccines causing autism spiking ~2009, we want to explore the rates of vaccinations over the past few years.\n",
    "\n",
    "For this tutorial, we will focus on Polio in the state of Illinois. Some potential end goals are:\n",
    "\n",
    "- Has there been an overall decrease in the vaccination rates?\n",
    "    - Looking at data from years ending in 2005, 2010, and 2015\n",
    "- What schools decreased the most from 2005 to 2015?\n",
    "- What vaccines decreased the most from 2005 to 2015?\n",
    "- OPTIONAL: What schools are at the highest risk of decreasing further?\n",
    "\n",
    "## Dataset information\n",
    "Our dataset will come from the Illinois State Board of Education. The dataset is the Immuniation School Survey from the Health Requirements/Student Health Data page. The link is: http://www.isbe.net/research/htmls/immunization.htm \n",
    "\n",
    "## Methodology (important)\n",
    "In order to get a quick sense of the impact of the media coverage ~2009, we decided to pull data from 3 years: 2004-2005, 2009-2010, and 2014-2015.\n",
    "\n",
    "To measure the impact, we will be looking at the percentage of immunized kids to see if the media decreased (or increased?) that amount at all. This percentage will be **number of kids immunized at the school / total kids enrolled at the school**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "For this tutorial we'll be using Pandas, so let's import that now. In addition, we usually also import Numpy (for other numerical operations) and Matplotlib (for easy plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# this line makes the plots appear in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format, Import, and Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we imported the data, we should note that we first pre-processed the raw data (Excel files from the website) by exporting the relevant sheets into CSV. We will now load these CSV files into Pandas.\n",
    "\n",
    "The reason we use CSV is because it is an very commonly used between file format that can be transitioned to and from many different software platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years 04-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by reading the school year of 2004-2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df04 = pd.read_csv('../data/immunization_04-05.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *head()* method is a quick way to see the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the above header information was imported incorrectly. The correct headers were imported into row 0. Because we are lazy, we will re-import the data and drop the first row instead of formatting this current version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the skiprows argument here because we don't need the first row\n",
    "df04 = pd.read_csv('../data/immunization_04-05.csv', skiprows=1)\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, the columns are correct but per our goals we only need the following columns:\n",
    "1. school distict\n",
    "2. school id\n",
    "3. total enrollment\n",
    "4. polio vaccinations\n",
    "\n",
    "One easy way to do this is to simply select the columns we want. This is done using the *ix[]* indexing function. This should be very familiar for people who used R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name the columns we want to keep, the only select those columns\n",
    "columns_to_keep = ['RCDT', 'School', 'Total Sch. Enroll.', 'Polio Prot.']\n",
    "df04 = df04.ix[:, columns_to_keep] # takes all rows, takes only the columns in the array columns_to_keep\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the first row has NaN. Looking back at the table above, this is because the original table has some extra rows for Counties e.g. \"Adams County\".\n",
    "\n",
    "Let's simply drop the NaNs in this table using the *dropna()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.dropna(inplace=True) # inplace=True replaces the previous data frame.\n",
    "                          # This is the same as df04 = df04.dropna(inplace=False)\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking just the first 5 rows, let's check out some summary statistics. This is done using the *describe()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also make take a look at the datatypes (e.g. string, number) of these columns using *dtypes()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, the two columns are supposed to be numerical, not strings (denoted here as objects).\n",
    "\n",
    "Let's convert these now. To convert an entire column, we use the *applymap()* method. This essentially takes each value of the column and applies the function. In our case, the function is to change the datatype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inplace isn't available for this function, thus asign manually\n",
    "cols = ['Total Sch. Enroll.', 'Polio Prot.']\n",
    "df04[cols] = df04[cols].applymap(lambda x: int(x))\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error shows that there's are values with commas, as a result Python can't automatically change it into an int.\n",
    "\n",
    "We have to remove the comma, then convert to int. We do this using the *replace()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same applymap() above, but our function replaces the string then converts\n",
    "df04[cols] = df04[cols].applymap(lambda x: int(x.replace(',', '')))\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try looking at the datatypes again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful. Now let's run those summary stats again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks fine so far.\n",
    "\n",
    "We can probably do the same things to the next datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years 09-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the 2004-2005 data is out of the way, let's continue to 2009-2010. We expect to be using the same methods and techniques as above.\n",
    "\n",
    "Import again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df09 = pd.read_csv('../data/immunization_09-10.csv')\n",
    "df09.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same header issue as before. Same fix as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df09 = pd.read_csv('../data/immunization_09-10.csv', skiprows=1)\n",
    "df09.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now we want just the polio columns again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name the columns we want to keep, the only select those columns\n",
    "columns_to_keep = ['RCDT', 'School', 'Total Sch. Enroll.', 'Polio Prot.']\n",
    "df09.ix[:, columns_to_keep].head() # takes all rows, takes only the columns in the array columns_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, this is because the columns are named differently than from the 04-05 dataset! We need to get the correct column names for this table. Let's see the column names first using the *columns* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df09.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# again, select the columns we want and only take those\n",
    "columns_to_keep = ['RCDTS', 'Enrollment', 'PolioProt']\n",
    "df09 = df09[columns_to_keep]\n",
    "# might as well remove NAs too.\n",
    "df09.dropna(inplace=True)\n",
    "df09.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a quick note here that in this dataset, school district and school ID were combined into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df09.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How nice, they're floats already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df09.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks fine too.\n",
    "\n",
    "Let's go to the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years 14-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14 = pd.read_csv('../data/Immunization_14-15.csv')\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are header issues again, but this seems different. Looks like we want RCDTS from row 0, and the rest from row 1.\n",
    "\n",
    "Instead of what we did before, let's modify this by manually taking the raw data we want, then renaming the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want rows from 2 to the end, we want columns 0, 3, and 8\n",
    "df14 = df14.ix[2:, [0, 3, 8]]\n",
    "df14.dropna(inplace=True)\n",
    "# now customize and set the names we want for the columns\n",
    "new_column_names = ['RCDTS', 'Enrolled', 'Protected']\n",
    "df14.columns = new_column_names\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. Lets run the summary stats again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['Enrolled', 'Protected']\n",
    "df14[cols] = df14[cols].applymap(lambda x: int(x.replace(',', '')))\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That max looks crazy. What RCDTS does it belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14.sort(columns='Enrolled', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a valid RCDTS... Looks like we can just dump the row with id=4876 using the *drop()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14 = df14.drop(4876, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better.\n",
    "\n",
    "And that should be the last fix for our data import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will concatenate the tables to create a single table that will contain all the necessary data for our analysis.\n",
    "\n",
    "We noticed from above that all of the tables have different columns names. This will have to be fixed so that the tables can be joined easily.\n",
    "\n",
    "Tables for 14-15 and 09-10 both only have 3 columns so let's merge those first.\n",
    "\n",
    "However, to keep track of where the data comes from, let's add a \"Year\" column to both.\n",
    "\n",
    "Adding a column is similar to adding a new field and dictionary i.e. using square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add year column with correct values\n",
    "df14['Year'] = 2014\n",
    "df14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df09['Year'] = 2009\n",
    "df09.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we rename the columns so that the DataFrames can be easily concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "columns = ['rcdts', 'enrollment', 'protected', 'year']\n",
    "df09.columns = columns\n",
    "df14.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate\n",
    "df = pd.concat([df14, df09])\n",
    "print df[:5] # print first 5, same functionally as head()\n",
    "print df[-5:] # print last 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looks like both our datasets are here then.\n",
    "\n",
    "Time to join the table from year 04-05.\n",
    "\n",
    "However, we remember that year 04-05 has 4 columns because school is broken out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we notice is that the years 04-05 have 'n/a' values for School... this poses a problem for future analyses. Without being sure of the School values, we're not comfortable comparing this year with the other 2 years.\n",
    "\n",
    "After much debate, we decided to remove school completely from our current analysis.\n",
    "\n",
    "Unfortunately, this means we will have to remove the School values from our other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.insert(1, 'rcdt', 0)\n",
    "df['rcdt'] = df['rcdts'].apply(lambda x: x[:-4]) # use apply here because Series does not have an applymap() method\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the RCDT column, we can drop the origina RCDTS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop old rcdts column\n",
    "df.drop('rcdts', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the master dataset prepped, let's clean up the 04-05 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_we_want = ['rcdt', 'enrollment', 'protected', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the school column\n",
    "df04.drop('School', axis=1, inplace=True)\n",
    "# add the year so we remember where this dataset came from\n",
    "df04['year'] = 2004\n",
    "# now rename the columns\n",
    "df04.columns = columns_we_want\n",
    "df04.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's concatenate this dataset into the master dataset, again using the *concat()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df04])\n",
    "print df[:5] # print first 5, same functionally as head()\n",
    "print df[-5:] # print last 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original goal of this analysis is to see if the protected percentage dropped over the years. Let's run this analysis, which shouldn't take long now that we have the data in the way we want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_year = df.groupby('year').aggregate({'enrollment':'sum', 'protected':'sum'})\n",
    "df_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_year['prot_perc'] = df_year['protected']/df_year['enrollment']\n",
    "df_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_year.prot_perc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like the rate of immunization has dropped a little over these years. However, with only 3 data points we can't be too certain. Best if we were to take the other years in between into account. That's for another time though."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
